{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPolisher(object):\n",
    "    \"\"\"\n",
    "    Class that holds functions to clean and prepare the NYT article data\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        # Dataframe to keep the data\n",
    "        self.data = pd.DataFrame()\n",
    "\n",
    "\n",
    "    def loaddata(self, folder):\n",
    "        \"\"\"\n",
    "        Loads the data\n",
    "        folder (string): folder in which to look for the datafiles\n",
    "        returns nothing\n",
    "        \"\"\"\n",
    "\n",
    "        # Loop over all sections\n",
    "        for idx, section in enumerate([\"Arts\", \"Business\", \"Food\", \"Health\", \"NY\", \"Politics\", \"RealEstate\", \"Science\", \"Sports\", \"Style\", \"Tech\", \"Travel\", \"US\", \"World\"]):\n",
    "\n",
    "            # Get files and set up empty dataframe and list\n",
    "            files = glob.glob(PATH_TO_REPO + folder + \"/Articles_\" + section + \"*.json\")\n",
    "            sectiondata = pd.DataFrame()\n",
    "            list_ = []\n",
    "\n",
    "            # Loop over all files, read data into dataframe and append to list\n",
    "            for file_ in files:\n",
    "                df = pd.read_json(file_)\n",
    "                list_.append(df)\n",
    "\n",
    "            # Combine all frames and label them\n",
    "            sectiondata = pd.concat(list_)\n",
    "            sectiondata[\"label\"] = idx\n",
    "\n",
    "            # Combine all on class' data variable\n",
    "            self.data = pd.concat([self.data,sectiondata])\n",
    "\n",
    "\n",
    "    def cleandata(self):\n",
    "        \"\"\"\n",
    "        Cleans the data\n",
    "        returns nothing\n",
    "        \"\"\"\n",
    "\n",
    "        # Drop empty entries\n",
    "        self.data = self.data.dropna(subset = ['allwords'])\n",
    "        print(self.data.columns)\n",
    "#         print(self.data.allwords)\n",
    "        # Drop all columns but \"allwords\" and \"label\", convert to string\n",
    "        self.data.drop(self.data.columns[[0,1,2,3,4,5,6,8,9,11]], axis=1, inplace=True)\n",
    "        print(self.data.columns)\n",
    "        print(\"dfdf\")\n",
    "        \n",
    "        self.data[\"allwords\"] = self.data[\"allwords\"].astype(str)\n",
    "\n",
    "        # Make length feature\n",
    "        self.data[\"length\"] = self.data[\"allwords\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "        # Drop all empty ones\n",
    "        self.data = self.data[self.data[\"length\"] != 0]\n",
    "\n",
    "        # Reset index and drop added column\n",
    "        self.data = self.data.reset_index()\n",
    "        self.data.drop('index', axis=1, inplace=True)\n",
    "\n",
    "        # Shuffle the dataframe, reset index and clean\n",
    "        self.data = self.data.reindex(np.random.permutation(self.data.index))\n",
    "        self.data = self.data.reset_index()\n",
    "        self.data.drop('index', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "    def writedata(self, filename):\n",
    "        \"\"\"\n",
    "        Writes the data to pickle\n",
    "        filename (string): filename for pickled datafile\n",
    "        returns nothing\n",
    "        \"\"\"\n",
    "\n",
    "        # Make folder for saving the data if it does not already exist\n",
    "        if not os.path.isdir(PATH_TO_REPO):\n",
    "            cmd = \"mkdir {}data\".format(PATH_TO_REPO)\n",
    "            os.system(cmd)\n",
    "\n",
    "        self.data.to_pickle(PATH_TO_REPO + filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"\n",
    "    Main function\n",
    "    \"\"\"\n",
    "    # Make class, then load, clean and write data\n",
    "    MyDataPolisher = DataPolisher()\n",
    "    MyDataPolisher.loaddata(folder = \"articles\")\n",
    "    MyDataPolisher.cleandata()\n",
    "    MyDataPolisher.writedata(filename = \"clean_nyt_training_data.pkl\")\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
